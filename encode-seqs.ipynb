{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FREQ_THRESHOLD = 10 # only care about \"words\" occuring at least than many training seqs\n",
    "REPLACE_MISSING_DICT_VALS_WITH='-7777777'\n",
    "USE_TEST_SET_FOR_TR = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir('out/'): os.makedirs('out/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate frequencies of words\n",
    "\n",
    "# word -> # of seqs it occures in occurences \n",
    "freqs = {}\n",
    "\n",
    "for x in train_df.Sequence:\n",
    "    for w in np.unique(x.split(',')):\n",
    "        if not freqs.has_key(w): freqs[w] = 0\n",
    "        freqs[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create dictionary (word -> ix)\n",
    "dictionary = {}\n",
    "i = 1 # start at 1\n",
    "\n",
    "for w in freqs.iterkeys():\n",
    "    if freqs[w] >= FREQ_THRESHOLD:\n",
    "        dictionary[w] = i\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add sentinel value for missing dict values\n",
    "assert(not dictionary.has_key(REPLACE_MISSING_DICT_VALS_WITH))\n",
    "dictionary[REPLACE_MISSING_DICT_VALS_WITH] = 1 + max(dictionary.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary size: 13822\n"
     ]
    }
   ],
   "source": [
    "np.save('out/dictionary@tr=%d.npy'%(FREQ_THRESHOLD), dictionary)\n",
    "print 'Dictionary size:', len(dictionary.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make sure ids are unique actoss training/test set\n",
    "train_ids = train_df['Id'].values\n",
    "test_ids = test_df['Id'].values\n",
    "assert(len(train_ids) + len(test_ids) == \\\n",
    "       len(np.unique(np.concatenate((train_ids, test_ids)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gen_encoded_sequences(df, dictionary, extract_last=False, fill_dict_misses_with=None):\n",
    "\n",
    "    max_len = -1\n",
    "    sequences = {} # id -> ix\n",
    "    last_items = {} # id -> ix\n",
    "\n",
    "    # encode sequences as indexes from dictionary\n",
    "    for ix, r in tqdm(df.iterrows()):\n",
    "        seq_id = r['Id']\n",
    "        words = r['Sequence'].split(',')\n",
    "\n",
    "        sequences[seq_id] = []\n",
    "\n",
    "        for w in words:\n",
    "            \n",
    "            if dictionary.has_key(w):\n",
    "                sequences[seq_id].append(dictionary[w])\n",
    "            else:\n",
    "                if fill_dict_misses_with is None:\n",
    "                    # if sequence contains word not in dictionary, skip it\n",
    "                    del sequences[seq_id]\n",
    "                    break\n",
    "                else:\n",
    "                    sequences[seq_id].append(fill_dict_misses_with)\n",
    "            \n",
    "        if sequences.has_key(seq_id):\n",
    "            \n",
    "            if extract_last:\n",
    "                last_items[seq_id] = sequences[seq_id].pop()\n",
    "\n",
    "            if max_len < len(sequences[seq_id]):\n",
    "                max_len = len(sequences[seq_id])\n",
    "            \n",
    "    return sequences, last_items, max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "227690it [00:19, 11465.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "101851"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if USE_TEST_SET_FOR_TR:\n",
    "    combined_tr_df = train_df.append(test_df)\n",
    "else:\n",
    "    combined_tr_df = train_df\n",
    "\n",
    "train_e_seq, train_e_last, train_max_len = \\\n",
    "    gen_encoded_sequences(combined_tr_df, dictionary=dictionary, extract_last=True)\n",
    "    \n",
    "len(train_e_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113845it [00:10, 11009.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "113845"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_e_seq, test_e_last, test_max_len = \\\n",
    "    gen_encoded_sequences(test_df, dictionary=dictionary, extract_last=False, \\\n",
    "                          fill_dict_misses_with=dictionary[REPLACE_MISSING_DICT_VALS_WITH])\n",
    "\n",
    "len(test_e_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101851it [00:02, 40799.56it/s]\n",
      "113845it [00:02, 42138.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# pad sequences to max_len\n",
    "max_len = max(train_max_len, test_max_len)\n",
    "\n",
    "print max_len; time.sleep(1)\n",
    "\n",
    "for seq_id, seq in tqdm(train_e_seq.iteritems()):\n",
    "    train_e_seq[seq_id] = np.array(train_e_seq[seq_id], dtype=np.int32)\n",
    "    train_e_seq[seq_id] = np.pad(train_e_seq[seq_id], (max_len - len(train_e_seq[seq_id]), 0), \\\n",
    "                                 'constant', constant_values = (0.,0.))\n",
    "\n",
    "for seq_id, seq in tqdm(test_e_seq.iteritems()):\n",
    "    test_e_seq[seq_id] = np.array(test_e_seq[seq_id], dtype=np.int32)\n",
    "    test_e_seq[seq_id] = np.pad(test_e_seq[seq_id], (max_len - len(test_e_seq[seq_id]), 0), \\\n",
    "                                 'constant', constant_values = (0.,0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save('out/train_e_seq@tr=%d.npy'%(FREQ_THRESHOLD), train_e_seq)\n",
    "np.save('out/train_e_last@tr=%d.npy'%(FREQ_THRESHOLD), train_e_last)\n",
    "np.save('out/test_e_seq@tr=%d.npy'%(FREQ_THRESHOLD), test_e_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
